# 手写数字生成

## 下载数据集 MNIST

见test1和test2代码

## 使用简单的LeNet作为判别器

* 输入层，1 * 28 * 28的张量
* 第一卷积层，6 * 1 * 5 * 5卷积核（6通道输出，每通道1 * 5 * 5），步幅1，填充2，ReLU激活
  步幅移动次数=28+2-(5-2)+1=28
  所以卷积层输出为6 * 28 * 28的特征张量
  在此步骤中，需要学习的参数包括：
  6 * 1 * 5 * 5=150 个卷积权重
  6个卷积核偏置
  一共156个参数
* 第一汇聚层，2 * 2汇聚窗口，步幅2，平均汇聚
  步幅移动次数=28/2=14
  所以汇聚层输出为6 * 14 * 14的特征张量
* 第二卷积层，16 * 6 * 5 * 5卷积核，步幅1，填充0，ReLU激活
  步幅移动次数=14+0-(5-0)+1=10
  所以卷积层输出为16 * 10 * 10的特征张量
  此步骤中，需要学习的参数包括：
  16 * 6 * 5 * 5=2400 个卷积权重
  16个卷积核偏置
  一共2416个参数
* 第二汇聚层，2 * 2汇聚窗口，步幅2，平均汇聚
  步幅移动次数=10/2=5
  所以汇聚层输出为16 * 5 * 5的特征张量
* 展平层 将16 * 5 * 5的特征张量展开为400向量
* 第一全连接层，400-->120，ReLU激活
* 第二全连接层，120-->84，ReLU激活
* 第三全连接层，84-->10

判别器定义和训练见：test3和test4

训练结果：

![LeNetGPUModelDef.png](ReadMePic%2FLeNetGPUModelDef.png)

## 使用全链接训练生成器

生成器输入：100维向量，随机生成
生成器输出：1 * 28 * 28向量
模型类型：全链接
模型参数：
  * 100 --> 28 * 28 全链接层参数，参数个数为100 * 28 * 28
  * ReLu激活
损失函数：
  * 判别器判别生成器的输出，得到一个10维向量
  * 从中取出最大值，认为是最接近的数字内容
  * 取这个最大值生成器生成图片的相似度
  * 对其取负，作为loss函数

## 实验及结果

1. 通过test6可以查到真实的图片输入到判别器中，loss为 -0.75 左右
2. 通过调整test5的训练速率得到生成器，生成器生成的loss经过判别器判别，loss在 -0.75 左右
![FCGenModelDef.png](ReadMePic%2FFCGenModelDef.png)
3. 实际观察此时生成的图片，并不像

失败分析：

生成器的模型参数应该只是上面生成器模型定义的全链接层的参数而已；

但是由于训练生成器的时候，使用了判别器forward函数，将随机生成的图片进行了判别

此时，判别器forword参与了生成器loss，造成了判别器的模型参数变成了生成器的一部分

并且反向传播的过程中更新了判别器的模型参数，使得每次判别判别器都不是之前参数设置

所以失败！

改进如下：

~~~
# 判别器模型参数不参与update
for justParams in self.justifyModel.parameters():
  justParams.requires_grad = False
~~~

通过将判别器和生成器彻底分开，发现上面test5的评价结论是错误的，真是图片上的loss是-30左右，重新训练

这样改进之后，又遇到了一个新问题：生成器loss始终难以下降

